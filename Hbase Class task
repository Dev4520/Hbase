#File loaded from local directry to LDF with help of Filezila.
Then file again loaded LDF to HDFS with help of cloudera
[cloudera@quickstart ~]$ ls /home/cloudera/Hbase1
o/p- sales_order_data.csv

#[cloudera@quickstart ~]$ hadoop fs -ls /user/Hbase_sale
o/p- -rw-r--r--   1 cloudera supergroup     360233 2023-02-14 02:33 /user/Hbase_sale/sales_order_data.csv

# crate data base to hive directary
hive> create database Hbase_hive;
o/p-OK
Time taken: 13.517 seconds

# show databases in hive
O/P- hive> show databases;
OK
default
hbase_hive

# use databases in hive
O/P- use hbase_hive;
OK

# create table in hive for data laod from hdfs to hive table
create table hbase_hive_sales_csv
(
ORDERNUMBER int,
QUANTITYORDERED int,
PRICEEACH float,
ORDERLINENUMBER int,
SALES float,
STATUS string,
QTR_ID int,
MONTH_ID int,
YEAR_ID int,
PRODUCTLINE string,
MSRP int,
PRODUCTCODE string,
PHONE string,
CITY string,
STATE string,
POSTALCODE string,
COUNTRY string,
TERRITORY string,
CONTACTLASTNAME string,
CONTACTFIRSTNAME string,
DEALSIZE string
)
row format delimited
fields terminated by ','
tblproperties("skip.header.line.count"="1");

# load data on hive table hbase_hive_sales_csv
hive> load data inpath '/user/Hbase_sale/sales_order_data.csv' into table hbase_hive_sales_csv;
O/P- Loading data to table hbase_hive.hbase_hive_sales_csv
Table hbase_hive.hbase_hive_sales_csv stats: [numFiles=1, totalSize=360233]
OK
Time taken: 1.354 seconds


















